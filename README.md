# Kaggle Competition: Titanic Survival Prediction
## A ML Practice Project
### Abstract
I came across [this](https://www.kaggle.com/competitions/titanic/overview) competition on Kaggle and was intrigued by the prompt. We received two datasets of Titanic passengers and compete to create the most accurate classification model. The evaluation metric for the competition is accuracy score, but I found that optimizing the AUC score gives me a model that does better with the competition test dataset than those that I found through optimizing accuracy score. 
### Learning Reflection
I enjoyed this project immensely. It was extremely fun wrangling the dataset and trying to preserve as much information as possible. I also briefly researched the Titanic event to obtain some domain knowledge that was helpful. I learned two new models (MLPC and SVC), and found the best model to be a hypertuned Random Forest Classifier (accuracy = 0.87, AUC = 0.84). <br>
What I am most proud of when working on this is the logic flow of the notebook and the way I recorded my decisions to come back and reassess them later.
### Data Sources
Kaggle provided the datasets. 
